{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Punctuation_Restoration_Demo.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Zms8enGoYAue",
        "btVU0QxoakgD"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Change the path to where your model is\n",
        "PATH_TO_MODEL = '/punctRestorationModel.pth'"
      ],
      "metadata": {
        "id": "4UGGoS8xiwip"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##IMPORTS"
      ],
      "metadata": {
        "id": "Zms8enGoYAue"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLuh5TbLZ-4K",
        "outputId": "e327af41-867c-4cde-cd06-7c5a3afdde02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 7.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 67.4 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 13.0 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 44.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.20.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the relevant modules\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re"
      ],
      "metadata": {
        "id": "xbUas5o_ahjy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, f1_score\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "import numpy as np\n",
        "import copy\n",
        "import random\n",
        "import time\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import (TensorDataset, DataLoader, RandomSampler, SequentialSampler)"
      ],
      "metadata": {
        "id": "2ZVtBKrLQVg4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "B-WzRlZocu6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Download model"
      ],
      "metadata": {
        "id": "btVU0QxoakgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, embedding_dim, n_filters, filter_sizes, output_dim, dropout, sent_len):\n",
        "        super().__init__()\n",
        "        self.sent_len = sent_len\n",
        "        \n",
        "        self.convs = nn.ModuleList([\n",
        "                                    nn.Conv2d(in_channels = 1, \n",
        "                                              out_channels = n_filters, \n",
        "                                              kernel_size = (sent_len//2, embedding_dim//fs),\n",
        "                                              stride = embedding_dim//fs//2\n",
        "                                              ) \n",
        "                                    for fs in filter_sizes\n",
        "                                    ])\n",
        "        \n",
        "        self.convs2 = nn.ModuleList([\n",
        "                                    nn.Conv2d(in_channels = 1, \n",
        "                                              out_channels = n_filters, \n",
        "                                              kernel_size = (sent_len//2, embedding_dim//fs),\n",
        "                                              stride = embedding_dim//fs//2\n",
        "                                              ) \n",
        "                                    for fs in filter_sizes\n",
        "                                    ])\n",
        "        \n",
        "        self.convs3 = nn.ModuleList([\n",
        "                                    nn.Conv2d(in_channels = 1, \n",
        "                                              out_channels = n_filters, \n",
        "                                              kernel_size = (2, embedding_dim//fs),\n",
        "                                              stride = embedding_dim//fs//2\n",
        "                                              ) \n",
        "                                    for fs in filter_sizes\n",
        "                                    ])\n",
        "        \n",
        "        \n",
        "        self.fc = nn.Linear(len(filter_sizes) * n_filters*3, len(filter_sizes) * n_filters)\n",
        "        self.fc2 = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.out = nn.Softmax(dim=0)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        embedded = text        \n",
        "        embedded = embedded.unsqueeze(1)\n",
        "        \n",
        "        conved = [F.elu(conv(embedded[:,:,6//2:,:])).squeeze(2) for conv in self.convs]\n",
        "        conved2 = [F.elu(conv(embedded[:,:,:6//2,:])).squeeze(2) for conv in self.convs2]\n",
        "        conved3 = [F.elu(conv(embedded[:,:,6//2-1:6//2+1,:])).squeeze(2) for conv in self.convs3]\n",
        "                \n",
        "        pooled = [F.avg_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "        pooled2 = [F.avg_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved2]\n",
        "        pooled3 = [F.avg_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved3]\n",
        "        \n",
        "        cat = self.dropout(torch.cat(pooled+pooled2+pooled3, dim = 1))\n",
        "\n",
        "        logits = self.dropout(self.fc(cat))\n",
        "        logits = self.fc2(logits)\n",
        "\n",
        "            \n",
        "        return logits"
      ],
      "metadata": {
        "id": "CmJedS0_0og6"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 768\n",
        "N_FILTERS = 25\n",
        "FILTER_SIZES = [1,2,4,6,8,12,16]\n",
        "DROPOUT = 0.5\n",
        "OUTPUT_DIM = 3\n",
        "\n",
        "modelPunct = CNN(EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, 6)\n",
        "modelPunct.load_state_dict(torch.load(PATH_TO_MODEL,map_location=torch.device('cpu')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQEe7kAW0vm1",
        "outputId": "76b4d866-bc48-47b4-f266-5a64c7c69179"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelBert = BertModel.from_pretrained(\"DeepPavlov/rubert-base-cased\", output_hidden_states = True,)\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVhCh6obauOi",
        "outputId": "89292ce9-059c-4959-d3e4-b11b9d3fbf69"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bert_text_preparation(text, tokenizer):\n",
        "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "    tokenized_text = tokenizer.tokenize(marked_text)\n",
        "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "    segments_ids = [1]*len(indexed_tokens)\n",
        "\n",
        "\n",
        "    # word_lens stores length of each word in input text, because some words get broken into multiple tokens\n",
        "\n",
        "    word_lens = []\n",
        "    for i in range(len(tokenized_text)):\n",
        "      token = tokenized_text[i]\n",
        "      if token[0:2] == \"##\":\n",
        "        word_lens[-1]+=1\n",
        "      elif tokenized_text[i-1] == '-':\n",
        "        word_lens[-2] += 2\n",
        "        word_lens.pop()\n",
        "      else:\n",
        "        word_lens.append(1)\n",
        "\n",
        "    # Convert inputs to PyTorch tensors\n",
        "    tokens_tensor = torch.tensor([indexed_tokens])\n",
        "    segments_tensors = torch.tensor([segments_ids])\n",
        "\n",
        "    return tokenized_text, tokens_tensor, segments_tensors, word_lens\n",
        "    \n",
        "def get_bert_embeddings(tokens_tensor, segments_tensors, word_lens, model):\n",
        "    with torch.no_grad():\n",
        "        outputs = model(tokens_tensor, segments_tensors)\n",
        "        # Removing the first hidden state\n",
        "        # The first state is the input state\n",
        "        hidden_states = outputs[2][1:]\n",
        "\n",
        "    token_embeddings = torch.stack(hidden_states, dim=0)\n",
        "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "    token_embeddings = token_embeddings.permute(1,0,2)\n",
        "\n",
        "\n",
        "    # Get embeddings from the last 3 layers of BERT and concatenate them \n",
        "    # For each words that is longer than one token, take the mean of all the token\n",
        "    # The resulting embedding size is 2304 for each word\n",
        "\n",
        "    list_token_embeddings = []\n",
        "    cur_index = 1\n",
        "    for i in range(1,len(word_lens)-1):\n",
        "      new_token = token_embeddings[cur_index:cur_index+word_lens[i],-4:,:]\n",
        "      new_token = torch.sum(new_token, dim=1)\n",
        "      new_token = torch.mean(new_token,0)\n",
        "      \n",
        "      new_token = new_token.flatten()\n",
        "      list_token_embeddings.append(new_token)\n",
        "      cur_index += word_lens[i]\n",
        "\n",
        "\n",
        "    return list_token_embeddings"
      ],
      "metadata": {
        "id": "aCoGwUKRayw-"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(train_inputs, train_labels, sent_len=20, embedding_size = 2304):\n",
        "    train_labels = torch.tensor(train_labels)\n",
        "    train_labels = train_labels.to(device)\n",
        "    \n",
        "    train_inputs = torch.concat((torch.zeros((sent_len//2-1,embedding_size),).to(device),\n",
        "                                 torch.stack(train_inputs).to(device),\n",
        "                                 torch.zeros((sent_len//2,embedding_size)).to(device)))\n",
        "  \n",
        "    train_labels = torch.concat((torch.zeros((sent_len//2-1),dtype=torch.long).to(device),\n",
        "                                 train_labels,\n",
        "                                 torch.zeros((sent_len//2),dtype=torch.long).to(device)))\n",
        "    \n",
        "    train_data = TensorDataset(train_inputs, train_labels)\n",
        "    \n",
        "    return train_data"
      ],
      "metadata": {
        "id": "wc9RlZeYSUWJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, val_data, sent_len, batch_size):\n",
        "  model.eval()\n",
        "\n",
        "  all_labels = []\n",
        "  all_preds = []\n",
        "  for i in range(0,len(val_data)-sent_len, batch_size):\n",
        "      batch = [tuple(t.to(device) for t in val_data[i+b:i+sent_len+b]) for b in range(batch_size) if i+sent_len+b <= len(val_data)]\n",
        "\n",
        "      b_input_ids = []\n",
        "      b_labels = []\n",
        "\n",
        "      for b in batch:\n",
        "        input, labels = b\n",
        "        if len(labels) != sent_len:\n",
        "          print(labels)\n",
        "        b_input_ids.append(input)\n",
        "        all_labels.append(int(labels[sent_len//2-1].item()))\n",
        "        b_labels.append(labels[sent_len//2-1])\n",
        "\n",
        "      b_labels = torch.stack(b_labels, dim=0)\n",
        "      b_input_ids = torch.stack(b_input_ids, dim=0)\n",
        "\n",
        "      with torch.no_grad():\n",
        "          logits = model(b_input_ids)\n",
        "\n",
        "      preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "      all_preds+=[int(i.item()) for i in preds]\n",
        "\n",
        "  return all_preds"
      ],
      "metadata": {
        "id": "H7Xl3FCyWL2P"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def restoreText(words,punct):\n",
        "  seps = [',','.','!','?']\n",
        "  restored = words.copy()\n",
        "  restored[0] = restored[0].title()\n",
        "  p_index = np.argwhere(np.array(punct)!=0).flatten()\n",
        "  for i in p_index:\n",
        "    restored[i] = restored[i] + seps[punct[i]-1]\n",
        "    if i < len(words)-1 and punct[i]-1!=0:\n",
        "      restored[i+1] = restored[i+1].title()\n",
        "  \n",
        "  return ' '.join(restored)"
      ],
      "metadata": {
        "id": "3lE3svZxae4S"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert datasets to X and y\n",
        "# X contains individual words. Numbers and punctuation marks are left out\n",
        "# y contains classes for each word, a class is the punctuation mark that comes after a word. For example - \"I like NLP!\" is [0,0,2]\n",
        "\n",
        "def process_text(text):\n",
        "  X = []\n",
        "  y = []\n",
        "\n",
        "  tokens = word_tokenize(text)\n",
        "\n",
        "  seps = [',','.','!','?']\n",
        "\n",
        "  for token in tokens:\n",
        "\n",
        "    if token in seps:\n",
        "      sInd = seps.index(token)+1\n",
        "      if sInd >= 2:\n",
        "        y[-1] = 2\n",
        "      else:\n",
        "        y[-1] = 1\n",
        "    else:\n",
        "      X.append(token.lower())\n",
        "      y.append(0)\n",
        "\n",
        "  return X, y"
      ],
      "metadata": {
        "id": "QjWIqcUXnVHT"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NATTnLI7bcU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PREDICT"
      ],
      "metadata": {
        "id": "19B9ozvlY9q5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''Он благополучно избегнул встречи с своею хозяйкой на лестнице. Каморка его приходилась под самою кровлей высокого пятиэтажного дома и походила более на шкаф, чем на квартиру. Квартирная же хозяйка его, у которой он нанимал эту каморку с обедом и прислугой, помещалась одною лестницей ниже, в отдельной квартире, и каждый раз, при выходе на улицу, ему непременно надо было проходить мимо хозяйкиной кухни, почти всегда настежь отворенной на лестницу. И каждый раз молодой человек, проходя мимо, чувствовал какое-то болезненное и трусливое ощущение, которого стыдился и от которого морщился. Он был должен кругом хозяйке и боялся с нею встретиться. Не то чтоб он был так труслив и забит, совсем даже напротив, но с некоторого времени он был в раздражительном и напряженном состоянии, похожем на ипохондрию.'''"
      ],
      "metadata": {
        "id": "waFCQZaqP6JZ"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = process_text(text)"
      ],
      "metadata": {
        "id": "BMM_sf-8m4km"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfhaAeBvORE3",
        "outputId": "a18e7132-0e05-4587-ffa4-3c6975444932"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['он', 'благополучно', 'избегнул', 'встречи', 'с', 'своею', 'хозяйкой', 'на', 'лестнице', 'каморка', 'его', 'приходилась', 'под', 'самою', 'кровлей', 'высокого', 'пятиэтажного', 'дома', 'и', 'походила', 'более', 'на', 'шкаф', 'чем', 'на', 'квартиру', 'квартирная', 'же', 'хозяйка', 'его', 'у', 'которой', 'он', 'нанимал', 'эту', 'каморку', 'с', 'обедом', 'и', 'прислугой', 'помещалась', 'одною', 'лестницей', 'ниже', 'в', 'отдельной', 'квартире', 'и', 'каждый', 'раз', 'при', 'выходе', 'на', 'улицу', 'ему', 'непременно', 'надо', 'было', 'проходить', 'мимо', 'хозяйкиной', 'кухни', 'почти', 'всегда', 'настежь', 'отворенной', 'на', 'лестницу', 'и', 'каждый', 'раз', 'молодой', 'человек', 'проходя', 'мимо', 'чувствовал', 'какое-то', 'болезненное', 'и', 'трусливое', 'ощущение', 'которого', 'стыдился', 'и', 'от', 'которого', 'морщился', 'он', 'был', 'должен', 'кругом', 'хозяйке', 'и', 'боялся', 'с', 'нею', 'встретиться', 'не', 'то', 'чтоб', 'он', 'был', 'так', 'труслив', 'и', 'забит', 'совсем', 'даже', 'напротив', 'но', 'с', 'некоторого', 'времени', 'он', 'был', 'в', 'раздражительном', 'и', 'напряженном', 'состоянии', 'похожем', 'на', 'ипохондрию']\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "if use_cuda:\n",
        "  model = modelPunct.cuda()\n",
        "else:\n",
        "  model = modelPunct.cpu()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a9KCH25PtW2",
        "outputId": "85859e85-9dca-4347-e7ef-8d32eee58508"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "tokenized_text, tokens_tensor, segments_tensors,word_lens = bert_text_preparation(\" \".join(X), tokenizer)\n",
        "embeddings = get_bert_embeddings(tokens_tensor.to(device), segments_tensors.to(device), word_lens, modelBert) \n",
        "data = prepare_data(embeddings,y,6,EMBEDDING_DIM)\n",
        "preds = predict(modelPunct,data,6,len(y))"
      ],
      "metadata": {
        "id": "JG_SDAiLN6jV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e30235b8-6f4b-44fe-e919-f7e154fa552c"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.02 s, sys: 606 µs, total: 1.02 s\n",
            "Wall time: 1.05 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text)\n",
        "print(restoreText(X,preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2RbUmRSbnQ1",
        "outputId": "4b9eee78-fc9d-44a3-9c1a-9e843ed17e9c"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Он благополучно избегнул встречи с своею хозяйкой на лестнице. Каморка его приходилась под самою кровлей высокого пятиэтажного дома и походила более на шкаф, чем на квартиру. Квартирная же хозяйка его, у которой он нанимал эту каморку с обедом и прислугой, помещалась одною лестницей ниже, в отдельной квартире, и каждый раз, при выходе на улицу, ему непременно надо было проходить мимо хозяйкиной кухни, почти всегда настежь отворенной на лестницу. И каждый раз молодой человек, проходя мимо, чувствовал какое-то болезненное и трусливое ощущение, которого стыдился и от которого морщился. Он был должен кругом хозяйке и боялся с нею встретиться. Не то чтоб он был так труслив и забит, совсем даже напротив, но с некоторого времени он был в раздражительном и напряженном состоянии, похожем на ипохондрию.\n",
            "Он благополучно избегнул встречи с своею хозяйкой на лестнице. Каморка его приходилась под самою кровлей высокого пятиэтажного дома и походила более на шкаф, чем на квартиру. Квартирная же хозяйка его, у которой он нанимал эту каморку с обедом и прислугой помещалась одною лестницей ниже в отдельной квартире. И каждый раз при выходе на улицу ему непременно надо было проходить мимо хозяйкиной кухни, почти всегда настежь, отворенной на лестницу, и каждый раз молодой человек, проходя мимо чувствовал какое-то болезненное и трусливое ощущение, которого стыдился и от которого морщился. Он был должен кругом хозяйке и боялся с нею встретиться. Не то, чтоб он был так труслив и забит, совсем даже напротив, но с некоторого времени он был в раздражительном и напряженном состоянии, похожем на ипохондрию.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JJXr3WdTg7YG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}